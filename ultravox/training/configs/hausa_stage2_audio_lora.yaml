# Stage 2: Fine-tune Whisper audio model using LoRA
# Load checkpoint from Stage 1, then add LoRA to audio model

text_model: "zai-org/GLM-4.6"
audio_model: "openai/whisper-large-v3-turbo"

# Load checkpoint from Stage 1 (update path after Stage 1 completes)
model_load_dir: "./output/checkpoint-<num_steps>"  # Update with actual checkpoint path

# Dataset configuration
# Use HuggingFace datasets (from vaghawan/hausa-audio-resampled)
train_sets:
  - name: hausa-huggingface-train
val_sets:
  - name: hausa-huggingface-val

val_dataset_args:
  max_samples: 64000  # Use all validation samples

loss_config:
  loss_function: "KL_Divergence"

# Enable LoRA for audio model (Whisper)
audio_model_lora_config:
  r: 8                    # LoRA rank (higher = more parameters, more capacity)
  lora_alpha: 16         # LoRA alpha (scaling factor, typically 2x rank)
  target_modules:        # Which modules to apply LoRA to
    - "k_proj"
    - "q_proj"
    - "v_proj"
    - "out_proj"

# Projector and LLM remain frozen
# text_model_lora_config: null  # LLM stays frozen

# Training configuration
max_steps: 500
batch_size: 8            # Per-GPU batch size (adjust based on GPU memory)
# Effective batch size = batch_size * num_gpus

# Learning rate configuration for LoRA fine-tuning
lr: 5e-5                 # Lower learning rate for fine-tuning
lr_warmup_steps: 50

# Multi-GPU configuration
use_fsdp: true  # Enable FSDP for multi-GPU training
bf16_training: true  # Enable bfloat16 mixed precision training

# Logging and saving configuration
logging_steps: 50        # Log metrics every 50 steps (integer = exact steps)
save_steps: 100          # Save checkpoint every 100 steps (integer = exact steps)
val_steps: 100           # Evaluate every 100 steps (integer = exact steps)

# Validation configuration
val_batch_size: 6        # Match training batch size (per GPU)
do_eval: true            # Enable evaluation on val_sets during training

report_logs_to: ["wandb"]
output_dir: "./output"

# HuggingFace Hub upload configuration
# Upload checkpoints to Hub after each save_steps (overrides previous uploads)
hub_upload_enabled: true
hub_repo: "vaghawan/hausa-ultravox-stage2"
hub_best_tag: "best"
hub_last_tag: "last"
hub_upload_best: true
hub_upload_last: true

