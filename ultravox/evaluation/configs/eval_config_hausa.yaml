# Evaluation config for Hausa conversation dataset
# Run separately after training completes (since do_eval: false with FSDP)
# Usage: poetry run python -m ultravox.evaluation.eval --config_path ultravox/evaluation/configs/eval_config_hausa.yaml

model: "hf://vaghawan/hausa-ultravox-stage-best"  # Update with your trained checkpoint path (or HF Hub path)

report_logs_to: ["wandb"]
output_dir: "./output/hausa_eval"

eval_sets:
  - name: hausa-huggingface-test  # Test split from HuggingFace dataset

eval_dataset_args:
  max_samples: 5  # Evaluate on all test samples, or set a limit like 1000

eval_batch_size: 1  # Match training batch size for consistency 24
eval_max_tokens: 512
eval_temperature: 0.0  # Deterministic generation (greedy decoding)

# Device and data type
device: "cuda"
data_type: "bfloat16"  # Use bfloat16 for A100 GPUs
use_fsdp: false  # Evaluation doesn't use FSDP (loads model normally)
use_tp: true
